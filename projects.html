<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="author" content="Ethan McCartney">
    <meta name="description" content="my website's projects page">
    <title>Ethan McCartney - Projects</title>
    <link rel="icon" href="images/site_icon.png">
    <link rel="stylesheet" href="main.css">
</head>

<body>
    <header>
        <h1 class="main_title">My Projects</h1>
        <p class="main_description">This is the page with all of my projects and project descriptions</p>

        <h2>Pages:</h2>
        <ul class="indent">
            <li>
                <a href="index.html">Home Page</a>
            </li>

            <li>
                <a href="about_me.html">About Me</a>
            </li>
        </ul>
    </header>

    <br>
    <hr>
    <br>

    <main>
        <h2>Quick Jump</h2>

        <p><span class="bold">*Note:</span> all of these projects listed are in cronological order, so the begining projects are quite old. I chose to leave it this way because I'm still proud of them, and they show all of the progress that I've made over the years.</p>

        <nav class="indent">
            <ul>
                <li>
                    <a href="#project1">Project #1</a> - <em>Space Raiders</em>
                </li>

                <li>
                    <a href="#project2">Project #2</a> - <em>Platform Jumper</em>
                </li>

                <li>
                    <a href="#project3">Project #3</a> - <em>GPU Web Scraper</em>
                </li>

                <li>
                    <a href="#project4">Project #4</a> - <em>Wordle Bot</em>
                </li>

                <li>
                    <a href="#project5">Project #5</a> - <em>Neural Network From Scratch</em>
                </li>

                <li>
                    <a href="#project6">Project #6</a> - <em>Visualizing an AI Learning</em>
                </li>

                <li>
                    <a href="#project7">Project #7</a> - <em>Game Engine from Scratch</em>
                </li>

                <li>
                    <a href="#project8">Project #8</a> - <em>Jarvis, Full stack development of LLM system integration</em>
                </li>

                <li>
                    <em>More to come in the future (still a work in progress)</em>
                </li>
            </ul>
        </nav>
        <br>

        <section id="project1">
            <h3>Project #1: Space Raiders<span class="date"> - (Fall 2020)</span></h3>
            <p><em>- Where it all began: my first program</em></p>

            <figure class="indent">
                <video src="videos/Space_Raiders.mp4" playsinline type="video/mp4" alt="Space Raiders Video" poster="images/Space_Raiders_Menu.png" loop autoplay muted></video>
                <figcaption><em>- Space Raiders Gameplay</em></figcaption>
            </figure>

            <p class="indent">
                &emsp;&emsp;This is my first ever program. In my senior year of highschool, starting from
                knowing nothing about python and almost nothing about programming in general, I decided to
                learn how to code, and ended up making this in a single day. It's a simple game that I call Space Raiders
                where you have to avoid an asteroid that speeds up overtime, and the longer you survive, the
                higher the score you earn. Here, you can see in the video some real gameplay of the game!
            </p>

            <p>
                <a href="#">Back to Top</a>
            </p>

        </section>
        <br>

        <section id="project2">
            <h3>Project #2: Platform Jumper<span class="date"> - (Spring 2021)</span></h3>
            <p ><em>- Video game round 2, improving on the last...</em></p>

            <figure class="indent">
                <video src="videos/Platform_Jumper.mp4" playsinline type="video/mp4" alt="Platform Jumper Video" poster="images/Platform_Jumper_Poster.png" loop autoplay muted></video>
                <figcaption><em>- Platform Jumper Gameplay</em></figcaption>
            </figure>

            <p class="indent">
                &emsp;&emsp;This is my second program that I have made, improving upon the last in both functionality
                and program complexity. It's another game just like the last, and the point of this game is to complete
                a level by making
                it from point A to B with out falling, or dying in some way. This game has much more complex features
                when compared
                to the last, here are a few:
            <ul class="indent">
                <li class="indent">
                    <em class="bold">Collision Detection:</em> dynamic hitbox algorithm that's used to calculate
                    collisions for any arbitrary defined object
                    allowing the creation of complex levels.
                </li>

                <br>

                <li class="indent">
                    <em class="bold">Particle Animation Algorithm:</em> Using the draw feature in the PyGame library, I
                    implemented an algorithm that displayed
                    a trailing particle effect where the particles had a decaying size relative to the random initial
                    size, and time alive.
                </li>

                <br>

                <li class="indent">
                    <em class="bold">infinitly Tiling Background:</em> implemented a infinitely tiling background where
                    the background tiles in order to create the
                    illusion of movement while being able to keep the background completely filled in without breaking
                    immersion.
                </li>
            </ul>
            </p>

            <p>
                <a href="#">Back to Top</a>
            </p>
        </section>
        <br>

        <section id="project3">
            <h3>Project #3: GPU Web Scraper<span class="date"> - (Spring/Summer 2021)</span></h3>
            <p><em>- Finding a modern GPU during a world-wide microchip shortage</em></p>

            <figure class="indent">
                <img src="images/GPU_Destroyer1.png" alt="GPU Scraper Code Image" width="100%"
                    loading="lazy">
                <figcaption><em>- GPU Web Scraper Code</em></figcaption>
            </figure>

            <p class="indent">
                &emsp;&emsp;After making two programs and building a custom PC, I needed a GPU for my PC to be able to
                further develop more ambitious projects in the future. However,
                this was during the peak of the 2021 world-wide chip shortage of the pandemic, where demand for such
                components were at a record high. So, I created a web scraper bot
                to autonomously monitor websites that sold the hardware component at MSRP. I learned a lot of valuable
                lessons about HTML5 along the way that eventually helped me to create this
                very website, but eventually after many close calls, the program succeeded twice securing two highly
                valuable GPU's (Radeon 6600xt & RTX 3060ti), where they were worth selling for twice that of which I paid.
            </p>

            <p>
                <a href="#">Back to Top</a>
            </p>
        </section>
        <br>

        <section id="project4">
            <h3>Project #4: Wordle Bot<span class="date"> - (Fall 2021 & Spring 2022)</span></h3>
            <p><em>- Destroying wordle with algorithms</em></p>

            <figure class="indent">
                <img class="center" src="images/Wordle_logo.png" alt="Wordle Logo Image" width="75%"
                    loading="lazy">
            </figure>

            <p class="indent">
                &emsp;&emsp;This project is able to beat wordle with a perfect <span class="bold">100%</span> accuracy. Using the ideas
                of information theory, the wordle algorithm goes through every possible guess calculating the number of average remaining words
                for each guess, and returns the words with the lowest average number of remaining words, or in other words, the words with the
                highest chance to eliminate the most remaining valid words. In simple terms, its essentually just an extremely optimized proccess 
                of elimination algorithm.
            </p>

            <p class="indent">
                All of the code for this project is available on my github <a href="https://github.com/Master-Pr0grammer/Wordle_Solver">Here</a>.
            </p>

            <p>
                <a href="#">Back to Top</a>
            </p>
        </section>
        <br>

        <section id="project5">
            <h3>Project #5: Neural Network From Scratch<span class="date"> - (Summer 2023)</span></h3>
            <p><em>- Implementing a neural network library completely from scratch</em></p>

            <figure>
                <img class="center" src="images/Neural_Network.jpg" alt="Wordle Logo Image" height = "500px"
                    loading="lazy">
            </figure>

            <p class="indent">
                &emsp;&emsp;This project is an implementation of a fully connected artificial neural
                network completely from scratch with the exception of the use of NumPy in order to
                speed up CPU-bound matrix calculations. Functionally, at its base level, it works the similarly as pytorch with
                the ability to define layers, and combine them together to create a network. 
            </p>

            <p class="indent">
                &emsp;&emsp;When you create a new network, it allows you to define the general structure of a neural
                network as a list of numbers where each element is a layer, and the value of each element is 
                the number of neurons in that layer. This is the default functionality, however internally, it represents
                the network as a list of layer objects, so you can manually create a network like pytorch has it implemented.
                As for the training, again it has the same functionality as Pytorch, but there is a default function that
                can be used to handle all of the training with one function call. This again can alternatively also be done manually
                for more control.
            </p>

            <p class="indent">
                All of the code for this project is available on my github <a href="https://github.com/Master-Pr0grammer/Neural_Network">Here</a>.
            </p>

            <p>
                <a href="#">Back to Top</a>
            </p>
        </section>
        <br>

        <section id="project6">
            <h3>Project #6: Visualizing AI Learning Algorithms<span class="date"> - (Summer 2023)</span></h3>
            <p><em>- Implementing a visual representation of a neural network learning</em></p>

            <figure class="indent">
                <video src="videos/AI_Learning.mp4" playsinline type="video/mp4" alt="AI Learning Visualization" poster="images/face.png" loop autoplay muted width="800px"></video>
                <figcaption><em>- AI Learning Visualization Video (10x slower than realtime)</em></figcaption>
            </figure>

            

            <p class="indent">
                &emsp;&emsp;This was somewhat of a continuation of my last project, in this project I generate a video representation
                of an AI learning an image, in the example above it's a simple smiley face, but it can be anything. The video is generated
                by sampling an image from the AI after every training step, then at the end of the training stringing the sampled images
                together to create a video. So you're literally watching an AI learn. 
            </p>

            <p class="indent">
                &emsp;&emsp;Originally, I had used my own code to create the neural network behind the AI, but due to the fact that it was
                CPU-bound proved to be much too slow, so after the original implementation, I opted to use PyTorch instead so that the Training could
                benefit from GPU powered acceleration via highly parallelized processing. 
            </p>

            <p class="indent">
                All of the code is available on my github <a href="https://github.com/Master-Pr0grammer/AI_Learning_Video">Here</a>.
            </p>

            <p>
                <a href="#">Back to Top</a>
            </p>
        </section>
        <br>

        <section id="project7">
            <h3>Project #7: Game Engine from Scratch<span class="date"> - (Fall 2023)</span></h3>
            <p><em>- Made a game engine from scratch in C++ using OpenGL</em></p>

            <figure class="indent">
                <div>
                    <video src="videos/Game_Engine_Demo.mp4" playsinline type="video/mp4" alt="Game Engine Demo" poster="images/Game_Engine_Demo_Pic.png" loop autoplay muted></video>
                </div>
                <figcaption><em>- Game Engine Demo</em></figcaption>
            </figure>

            

            <p class="indent">
                &emsp;&emsp;Made a Game engine from scratch in C++ using OpenGL for the GPU acceleration interface, and some simple linear algebra. The game engine supports Mac, Windows, and Linux; and features the ability 
                to load in 3d models, a camera object, the ability to create and manipulate objects and object physics, and a very simple light engine.
            </p>


            <p>
                <a href="#">Back to Top</a>
            </p>
        </section>
        <br>

        <section id="project8">
            <h3>Project #8: Self-Hosted LLM Server & LLM System Integration<span class="date"> - (Summer 2024)</span></h3>
            <p><em>- Built a physical server to host a Large Language Model (LLM), and designed and implemented back-end architecture with an API and a user-friendly front-end web application interface.</em></p>

            <figure class="indent">
                <video src="videos/Jarvis_Demo.mp4" playsinline type="video/mp4" alt="Jarvis Demo" poster="images/Jarvis_Demo_Pic.png" loop autoplay muted></video>
                <figcaption><em>- Jarvis Web-app Demo</em></figcaption>
            </figure>

            

            <p class="indent">
                &emsp;&emsp;Impressed by the release of ChatGPT, I decided to try out Large Language Models (LLM) for myself. I wanted it to be able to not just answer questions, 
                but to also be able to do things that would be useful like storing long term memories to better serve the user, reading my documents, doing automated google searches, 
                or doing complex calculations. I decided to go with using self hosted, open source LLMs to lower the cost to 0, and to prevent changes in the model for server-side closed source solutions like 
                ChatGPT, which happens quite often. So I had to do three things to accomplish this, Build a server to host/run the LLM, develope the back-end framework for the LLM system integration, and 
                finally, build a user-friendly front-end that is easy to use.
            </p>

            <p class="indent">
                &emsp;&emsp; For the server, I decided to build it myself rather than buy a pre-built server to more optimally fit my needs, and to lower costs. I was able to get the majority of the less important parts for 
                free, or dirt cheap off ebay. In the end, the only parts I paid for were the case, motherboard, and storage. More specifically hardware wise, to power the LLM, the server has a GTX 1080ti GPU. The server is 
                running an Ubuntu server that I can easily SSH into, and I am using "Twingate", which is similar to a VPN, so I can access the server from anywhere.
            </p>

            <p class="indent">
                &emsp;&emsp; As for the back-end, I decided to first design an API using Fast-API to interact with the LLM, so I can use the LLM, or the whole LLM system, for any other projects in the future. To do this, I mimicked the specifications 
                for the OpenAI API because this is the most widely used format for interfacing directly with LLMs, and then I can easily switch between different open source models, and different closed source models, 
                allowing for easy future model upgrades. Once I had this done, I decided on using Llamma 3 (8 billion parameters) since it is largely the most capable model at the moment, and was trained on by far the most data. 
                After designing the back-end, I gave the LLM the ability to use different "functions" which you can think of as actions, such as search. For example the search function gives the model the 
                ability to search for a query on google, local documents (from user), and the chat history using RAG. RAG, or Retrieval Augmented Generation takes a document (just a group of text), and splits it up into roughly paragraph sized chunks that are converted into 1024 dimensional vectors that maintain the same meaning as the text. Then once you have all the vectors, 
                you can simply do a vector similarity search using cosine similarity between the embedding vector, and an embedding vector of a search query. The vector with the highest similarity is returned as the result, and is used to guide the LLMs 
                final answer. The important thing about the implementation of these "functions" is that it is incredibly easy to implement any other function you want for full customization. 
                <br>
                <br>
                Here is a list of all of the default functions I have already implemented:
                <ul style = "margin-left: 3.75em;" >
                    <li>
                        <b>Search</b> - can search google, local documents, or long term chat history
                    </li>
    
                    <li>
                        <b>Calculator</b> - can be used to calculate any expresion
                    </li>

                    <li>
                        <b>toggle audio</b> - can toggle the state of the audio (TTS)
                    </li>

                    <li>
                        <b>Clear memory</b> - can be used to clear the short term chat history memory (useful for unrelated conversations, and more concentrated responses)
                    </li>
    
                    <li>
                        <b>Send Log</b> - Sends the current error log for debugging purposes
                    </li>
    
                    <li>
                        <b>List Functions</b> - Display's all of the above functions, and a short description
                    </li>
                </ul>
            </p>

            <p class="indent">
                &emsp;&emsp; Finally for the front-end, I started off by implementing Jarvis as a Discord chatbot, which worked well, but is limited for some features 
                so I settled on making a custom web-app so I had full control over all of the features, and I can host it using the same server hosting the LLM interface API. 
                I built the front-end using flask, and basic HTML, CSS, and JavaScript.
            </p>

            <p>
                <a href="#">Back to Top</a>
            </p>
        </section>
        <br>

    </main>

    <br>
    <hr>

    <p>
        <a href="#">Back to Top</a>
    </p>
</body>

</html>
